{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebScraping on ImmoWelt.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import bs4\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import ResultSet\n",
    "from bs4.element import Tag as HtmlTag\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUY_CATEGORIES = [\"kaufen\"]  # [\"kaufen\", \"mieten\"]\n",
    "PROPERTY_CATEGORIES = [\"wohnungen\", \"haeuser\"]\n",
    "HITS_PER_PAGE = 20\n",
    "BASE_URL = \"https://www.immowelt.de/liste/${state}/${property_category}/${buy_category}?d=true&efs=NEW_BUILDING_PROJECT&sd=DESC&sf=RELEVANCE&sp=${page}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bl-baden-wuerttemberg',\n",
       " 'bl-bayern',\n",
       " 'bl-berlin',\n",
       " 'bl-brandenburg',\n",
       " 'bl-bremen',\n",
       " 'bl-hamburg',\n",
       " 'bl-hessen',\n",
       " 'bl-mecklenburg-vorpommern',\n",
       " 'bl-niedersachsen',\n",
       " 'bl-nordrhein-westfalen',\n",
       " 'bl-rheinland-pfalz',\n",
       " 'bl-saarland',\n",
       " 'bl-sachsen',\n",
       " 'bl-sachsen-anhalt',\n",
       " 'bl-schleswig-holstein',\n",
       " 'bl-thueringen']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = \"Baden-Württemberg, Bayern, Berlin, Brandenburg, Bremen, Hamburg, Hessen, Mecklenburg-Vorpommern, Niedersachsen, Nordrhein-Westfalen, Rheinland-Pfalz, Saarland, Sachsen, Sachsen-Anhalt, Schleswig-Holstein, Thüringen\"\n",
    "states = states.replace(\"ü\", \"ue\").lower().split(\", \")\n",
    "STATES = [f\"bl-{state}\" for state in states]\n",
    "STATES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Plan\n",
    "\n",
    "<ol>\n",
    "    <li>Get list of Properties</li>\n",
    "    <li>Calculate the total Property pages count</li>\n",
    "    <li>Get list of Expose URLs of the page</li>\n",
    "    <li>Navigate to the Page and grab the Infos you want</li>\n",
    "    <li>Loop</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImmoWeltScraper:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_url: str,\n",
    "        states: list[str],\n",
    "        hits_per_page: int,\n",
    "        property_categories: list[str],\n",
    "        buy_categories: list[str],\n",
    "    ) -> None:\n",
    "        self.TIME_DELAY = 60 * 2.5\n",
    "        self.driver: webdriver.Chrome = None\n",
    "\n",
    "        self.base_url = base_url\n",
    "        self.states = states\n",
    "        self.hits_per_page = hits_per_page\n",
    "        self.property_categories = property_categories\n",
    "        self.buy_categories = buy_categories\n",
    "    \n",
    "    def scrape(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            self._create_driver()\n",
    "            df = self._scrape()\n",
    "            self._log(\"Script successful finished!\", \"SUCCESS\")\n",
    "        except Exception as exp:\n",
    "            self._destroy_driver()\n",
    "            self._log(\"Script failed. Try again!\", \"ERR\")\n",
    "            self._log(str(exp), \"ERR_MSG\")\n",
    "            # raise exp\n",
    "    \n",
    "    def _scrape(self) -> pd.DataFrame:\n",
    "        total_loops = len(self.states) * len(self.property_categories) * len(self.buy_categories)\n",
    "        curr_loop = 0\n",
    "        total_property_data: list[dict] = []\n",
    "        for state in self.states:\n",
    "            state_property_data: list[dict] = []\n",
    "            for property_category in self.property_categories:\n",
    "                for buy_category in self.buy_categories:\n",
    "                    curr_loop += 1\n",
    "                    self._log(f\"Current-Loop: {curr_loop} of {total_loops}\")\n",
    "                    url = self._get_prep_url(state, property_category, buy_category)\n",
    "                    soup = self._navigate_to(url)\n",
    "                    if not self._is_page_found(soup):\n",
    "                        continue\n",
    "                    \n",
    "                    page_count = self._calc_total_relevant_page_count(soup)\n",
    "                    page_count = 30 if page_count > 30 else page_count\n",
    "                    # page_count = 2 if page_count > 2 else page_count  # just for testing\n",
    "                    for i in range(0, page_count):\n",
    "                        page = i + 1\n",
    "                        self._log(f\"State: {state}, category: {property_category}, type: {buy_category}, page: {page} of {page_count}\")\n",
    "                        page_url = self._get_prep_url_page(url, page)\n",
    "                        soup = self._navigate_to(url)\n",
    "\n",
    "                        expose_urls = self._get_expose_urls(soup)\n",
    "                        for expose_url in expose_urls:\n",
    "                            self.driver.get(expose_url)\n",
    "                            property_data = self._get_property_data(\n",
    "                                property_category,\n",
    "                                buy_category,\n",
    "                                state\n",
    "                            )\n",
    "                            state_property_data.append(property_data)\n",
    "                            total_property_data.append(property_data)\n",
    "                self._log(f\"Category delay of {self.TIME_DELAY}s\", \"SLEEP\")\n",
    "                time.sleep(self.TIME_DELAY)\n",
    "            filepath = f\"./data/property_immowelt_{state}.csv\"\n",
    "            _ = self._export(state_property_data, filepath)\n",
    "            self._log(f\"State delay of {self.TIME_DELAY}s\", \"SLEEP\")\n",
    "            time.sleep(self.TIME_DELAY)\n",
    "        filepath = \"./data/property_immowelt_data.csv\"\n",
    "        return self._export(total_property_data, filepath)\n",
    "\n",
    "    def scrape_obj_test(\n",
    "        self,\n",
    "        expose_url: str,\n",
    "    ) -> dict:\n",
    "        self._create_driver()\n",
    "        soup = self._navigate_to(expose_url)\n",
    "        property_data = self._get_property_data(\n",
    "            soup,\n",
    "            \"property_category\",\n",
    "            \"buy_category\",\n",
    "            \"state\"\n",
    "        )\n",
    "        self._destroy_driver()\n",
    "        return property_data\n",
    "\n",
    "    def _create_driver(self) -> None:\n",
    "        if self.driver:\n",
    "            self._destroy_driver()\n",
    "        options = Options()\n",
    "        options.add_argument(\"--headless\")\n",
    "        self.driver = webdriver.Chrome(\n",
    "            service=Service(\n",
    "                ChromeDriverManager().install()\n",
    "            ),\n",
    "            options=options\n",
    "        )\n",
    "        self._log(\"Driver created\")\n",
    "        self._check_permission_requirements()\n",
    "        self._log(\"Permissions accepted\")\n",
    "\n",
    "    def _destroy_driver(self) -> None:\n",
    "        self._log(\"Destroy driver\")\n",
    "        if not self.driver:\n",
    "            return\n",
    "        self.driver.close()\n",
    "        self.driver = None\n",
    "\n",
    "    def _check_permission_requirements(self, err_loop: int = 0):\n",
    "        try:\n",
    "            self.driver.get(\"https://www.immowelt.de/immobilienpreise\")\n",
    "            check_element = None\n",
    "            while not check_element:\n",
    "                check_element = self.driver.execute_script(\n",
    "                    \"\"\"return document.querySelector('#usercentrics-root').shadowRoot.querySelector(\"button[data-testid='uc-accept-all-button']\")\"\"\"\n",
    "                )\n",
    "                if check_element:\n",
    "                    check_element.click()\n",
    "                else:\n",
    "                    self._log(\"Permission loop. Wait 2 seconds.\")\n",
    "                    time.sleep(2)\n",
    "        except Exception as exp:\n",
    "            err_loop += 1\n",
    "            if err_loop == 5:\n",
    "                raise exp\n",
    "            self._log(f\"Permission ERR#{err_loop}-loop\", \"WARN\")\n",
    "            self._check_permission_requirements(err_loop)\n",
    "\n",
    "    def _export(self, data: list[dict], filepath: str) -> pd.DataFrame:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.replace(\"|\", \"_\", inplace=True)\n",
    "        df.to_csv(filepath, sep=\"|\", index=False)\n",
    "        self._log(f\"CSV-Export to: {filepath}\")\n",
    "        return df\n",
    "\n",
    "    def _navigate_to(self, url: str) -> BeautifulSoup:\n",
    "        self.driver.get(url)\n",
    "        return BeautifulSoup(self.driver.page_source)\n",
    "\n",
    "    def _is_page_found(self, soup: BeautifulSoup) -> bool:\n",
    "        is_page_found = not soup.find(\"div\", {\"class\": \"NotFound-d39a0\"})\n",
    "        if not is_page_found:\n",
    "            url = self.driver.current_url\n",
    "            self._log(f\"Page not Found: {url}\", \"ERROR\")\n",
    "        return is_page_found\n",
    "\n",
    "    def _log(self, msg: str, tag: str = \"INFO\") -> None:\n",
    "        tag = tag.upper()\n",
    "        ts = datetime.now().strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "        print(f\"[{ts}] {tag}:\\t{msg}\")\n",
    "\n",
    "    def _get_prep_url(\n",
    "        self,\n",
    "        state: str,\n",
    "        property_category: str,\n",
    "        buy_category: str,\n",
    "        page: int = 1\n",
    "    ) -> str:\n",
    "        page = str(page)\n",
    "        return (\n",
    "            self.base_url\n",
    "                .replace(\"${state}\", state)\n",
    "                .replace(\"${property_category}\", property_category)\n",
    "                .replace(\"${buy_category}\", buy_category)\n",
    "                .replace(\"${page}\", page)\n",
    "        )\n",
    "\n",
    "    def _get_prep_url_page(self, url: str, page: int) -> str:\n",
    "        url_page_removed = url[:url.find(\"sp=\")]\n",
    "        return f\"{url_page_removed}sp={page}\"\n",
    "\n",
    "    def _calc_total_relevant_page_count(self, soup: BeautifulSoup) -> int:\n",
    "        hits_emt = soup.find(\"h1\", {\"class\": \"MatchNumber-a225f\"})\n",
    "        if not hits_emt:\n",
    "            return 0\n",
    "        content = hits_emt.text\n",
    "        hits = content[:content.find(\" \")].replace(\".\", \"\")\n",
    "        page_count = int(int(hits) / self.hits_per_page)\n",
    "        return page_count\n",
    "\n",
    "    def _get_expose_urls(self, soup: BeautifulSoup) -> list[str]:\n",
    "        expose_urls_emt = soup.find_all(\"a\", {\"class\": \"mainSection-b22fb\"})\n",
    "        expose_urls = [link[\"href\"] for link in expose_urls_emt]\n",
    "        return expose_urls\n",
    "\n",
    "    def _expand_read_more_areas(self, err_loop = 0) -> BeautifulSoup:\n",
    "        try:\n",
    "            script_expand_all_read_more = \"\"\"\n",
    "            let links = document.getElementsByClassName(\"link--read-more\");\n",
    "            while(links.length > 0) {\n",
    "                links[0].click(); \n",
    "                links = document.getElementsByClassName(\"link--read-more\");\n",
    "            }\n",
    "            \"\"\"\n",
    "            self.driver.execute_script(script_expand_all_read_more)\n",
    "            return BeautifulSoup(self.driver.page_source)\n",
    "        except Exception as exp:\n",
    "            print(\"EXEPTION!!\")\n",
    "            if err_loop >= 5:\n",
    "                raise exp\n",
    "            err_loop += + 1\n",
    "            self._log(f\"Can't expand read-more. Try: {err_loop} of 5\", \"WARN\")\n",
    "            self._expand_read_more_areas(err_loop)\n",
    "\n",
    "    def _get_overview_container(self, soup: BeautifulSoup) -> HtmlTag:\n",
    "        return soup.find(\"app-objectmeta\", {\"id\": \"aUebersicht\"})\n",
    "    \n",
    "    def _get_data_title(self, overview_container: HtmlTag) -> str:\n",
    "        emt = overview_container.find(\"h1\", {\"class\": \"ng-star-inserted\"})\n",
    "        return emt.text if emt else \"Na\"\n",
    "    \n",
    "    def _get_data_hardfacts(self, overview_container: HtmlTag) -> tuple[str, str, str]:\n",
    "        hardfact_emts = overview_container.find_all(\"div\", {\"class\": \"hardfact ng-star-inserted\"})\n",
    "\n",
    "        def prep_text(emt):\n",
    "            content: str = emt.text.strip()\n",
    "            return content[:content.find(\" \")]\n",
    "\n",
    "        price = prep_text(hardfact_emts[0])\n",
    "        living_space = prep_text(hardfact_emts[1])\n",
    "        rooms = prep_text(hardfact_emts[2])\n",
    "        \n",
    "        return price, living_space, rooms\n",
    "    \n",
    "    def _get_data_badges(self, overview_container: BeautifulSoup) -> str:\n",
    "        badge_emts = overview_container.find_all(\"sd-badge\")\n",
    "        badges = \"Na\"\n",
    "        if badge_emts:\n",
    "            badges = \";\".join([legal_info.text for legal_info in badge_emts])\n",
    "        return badges\n",
    "\n",
    "    def _get_data_ratings(self, soup: BeautifulSoup) -> tuple[str, str]:\n",
    "        rating_emts = soup.find_all(\"div\", {\"class\": \"rating-meter__value\"})\n",
    "        location_rating = \"Na\"\n",
    "        public_transport_rating = \"Na\"\n",
    "        if len(rating_emts) == 2:\n",
    "            location_rating = rating_emts[0].text\n",
    "            public_transport_rating = rating_emts[1].text\n",
    "        return location_rating, public_transport_rating\n",
    "\n",
    "    def _get_data_equipments(self, soup: BeautifulSoup) -> str:\n",
    "        equipment_container = soup.find(\"div\", {\"class\": \"equipment card-content ng-star-inserted\"})\n",
    "        if not equipment_container:\n",
    "            return \"Na\"\n",
    "\n",
    "        equipment_cells = equipment_container.find_all(\"sd-cell-row\", {\"class\": \"cell__row\"})\n",
    "        if not equipment_cells:\n",
    "            return \"Na\"\n",
    "\n",
    "        equipments = \"\"\n",
    "        equipment_cell: HtmlTag\n",
    "        for equipment_cell in equipment_cells:\n",
    "            values = equipment_cell.find_all(\"p\")\n",
    "            if len(values) >= 2:\n",
    "                title = values[0].text\n",
    "                value = values[1].text\n",
    "                equipments += f\"{title}: {value};\"\n",
    "\n",
    "        return equipments[:len(equipments)-1] if equipments else \"Na\"\n",
    "    \n",
    "    def _get_data_features(self, soup: BeautifulSoup) -> str:\n",
    "        feature_list_emts = soup.find_all(\"div\", {\"class\": \"textlist\"})\n",
    "        if not feature_list_emts:\n",
    "            return \"Na\"\n",
    "        features = \"\"\n",
    "        feature_list_emt: HtmlTag\n",
    "        for feature_list_emt in feature_list_emts:\n",
    "            feature_emts = feature_list_emt.find_all(\"li\")\n",
    "            if feature_emts:\n",
    "                feature_emt: HtmlTag\n",
    "                for feature_emt in feature_emts:\n",
    "                    features += f\"{feature_emt.text.strip()};\"\n",
    "\n",
    "        return features[:len(features)-1]\n",
    "\n",
    "    def _get_data_energy_data(self, soup: BeautifulSoup) -> str:\n",
    "        energy_data = \"\"\n",
    "\n",
    "        def get_data(curr_energy_data: str, energy_cells: ResultSet) -> str:\n",
    "            if not energy_cells:\n",
    "                return curr_energy_data\n",
    "\n",
    "            energy_cell: HtmlTag\n",
    "            for energy_cell in energy_cells:\n",
    "                content_emts = energy_cell.find_all(\"p\")\n",
    "                title = content_emts[0].text\n",
    "                content = content_emts[1].text\n",
    "                curr_energy_data += f\"{title}: {content};\"\n",
    "\n",
    "            return curr_energy_data\n",
    "\n",
    "        energy_container1 = soup.find(\"app-energy-equipment\")\n",
    "        if energy_container1:\n",
    "            energy_cells = energy_container1.find_all(\"sd-cell-col\", {\"data-cy\": \"energy-equipment\"})\n",
    "            energy_data = get_data(energy_data, energy_cells)\n",
    "\n",
    "        energy_container2 = soup.find(\"div\", {\"class\": \"energy_information ng-star-inserted\"})\n",
    "        if energy_container2:\n",
    "            energy_cells = energy_container2.find_all(\"sd-cell-col\", {\"class\": \"cell__col\"})\n",
    "            energy_data = get_data(energy_data, energy_cells)\n",
    "\n",
    "        return energy_data[:len(energy_data)]\n",
    "\n",
    "    def _get_data_keywords(self, soup: BeautifulSoup) -> str:\n",
    "        read_more_emts = soup.find_all(\"sd-read-more\")\n",
    "        keywords = \"Na\"\n",
    "        if not read_more_emts:\n",
    "            return keywords\n",
    "\n",
    "        last_emt_idx = len(read_more_emts) - 1\n",
    "        keywords: str = read_more_emts[last_emt_idx].text\n",
    "        KEYWORDS_NAME = \"Stichworte\"\n",
    "        if not KEYWORDS_NAME in keywords:\n",
    "            return keywords\n",
    "        start_idx = keywords.find(KEYWORDS_NAME) + len(KEYWORDS_NAME)\n",
    "        keywords = keywords[start_idx:]\n",
    "        return keywords\n",
    "\n",
    "    def _get_property_data(\n",
    "        self,\n",
    "        category: str,\n",
    "        buy_rent: str,\n",
    "        state: str,\n",
    "    ) -> dict:\n",
    "        soup = self._expand_read_more_areas()\n",
    "        overview_container = self._get_overview_container(soup)\n",
    "\n",
    "        url = self.driver.current_url\n",
    "        title = self._get_data_title(overview_container)\n",
    "        price, living_space, rooms = self._get_data_hardfacts(overview_container)\n",
    "        badges = self._get_data_badges(overview_container)\n",
    "        rating_location, rating_public_transport = self._get_data_ratings(soup)\n",
    "        equipments = self._get_data_equipments(soup)\n",
    "        features = self._get_data_features(soup)\n",
    "        energy_data = self._get_data_energy_data(soup)\n",
    "        keywords = self._get_data_keywords(soup)\n",
    "\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"category\": category,\n",
    "            \"buy_rent\": buy_rent,\n",
    "            \"state\": state,\n",
    "            \"title\": title,\n",
    "            \"price\": price,\n",
    "            \"living_space\": living_space,\n",
    "            \"rooms\": rooms,\n",
    "            \"badges\": badges,\n",
    "            \"rating_location\": rating_location,\n",
    "            \"rating_public_transport\": rating_public_transport,\n",
    "            \"equipments\": equipments,\n",
    "            \"features\": features,\n",
    "            \"energy_data\": energy_data,\n",
    "            \"keywords\": keywords\n",
    "            # image_paths: str,  # later the saved paths!\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 7.82M/7.82M [00:11<00:00, 731kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-12-17, 09:16:41] INFO:\tDriver created\n",
      "[2022-12-17, 09:16:43] INFO:\tPermission loop. Wait 2 seconds.\n",
      "[2022-12-17, 09:16:45] INFO:\tPermissions accepted\n",
      "[2022-12-17, 09:16:45] INFO:\tCurrent-Loop: 1 of 32\n",
      "[2022-12-17, 09:16:47] INFO:\tState: bl-baden-wuerttemberg, category: wohnungen, type: kaufen, page: 1 of 30\n",
      "[2022-12-17, 09:17:09] INFO:\tState: bl-baden-wuerttemberg, category: wohnungen, type: kaufen, page: 2 of 30\n",
      "[2022-12-17, 09:17:24] INFO:\tState: bl-baden-wuerttemberg, category: wohnungen, type: kaufen, page: 3 of 30\n",
      "[2022-12-17, 09:17:41] INFO:\tState: bl-baden-wuerttemberg, category: wohnungen, type: kaufen, page: 4 of 30\n",
      "[2022-12-17, 09:17:58] INFO:\tState: bl-baden-wuerttemberg, category: wohnungen, type: kaufen, page: 5 of 30\n",
      "[2022-12-17, 09:18:13] INFO:\tState: bl-baden-wuerttemberg, category: wohnungen, type: kaufen, page: 6 of 30\n",
      "[2022-12-17, 09:18:28] INFO:\tState: bl-baden-wuerttemberg, category: wohnungen, type: kaufen, page: 7 of 30\n",
      "[2022-12-17, 09:18:48] INFO:\tState: bl-baden-wuerttemberg, category: wohnungen, type: kaufen, page: 8 of 30\n",
      "[2022-12-17, 09:19:03] INFO:\tState: bl-baden-wuerttemberg, category: wohnungen, type: kaufen, page: 9 of 30\n",
      "[2022-12-17, 09:19:20] INFO:\tState: bl-baden-wuerttemberg, category: wohnungen, type: kaufen, page: 10 of 30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m immo_scraper \u001b[39m=\u001b[39m ImmoWeltScraper(\n\u001b[1;32m      2\u001b[0m     BASE_URL,\n\u001b[1;32m      3\u001b[0m     STATES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     BUY_CATEGORIES\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m immo_scraper\u001b[39m.\u001b[39;49mscrape()\n",
      "Cell \u001b[0;32mIn [5], line 22\u001b[0m, in \u001b[0;36mImmoWeltScraper.scrape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_driver()\n\u001b[0;32m---> 22\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_scrape()\n\u001b[1;32m     23\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log(\u001b[39m\"\u001b[39m\u001b[39mScript successful finished!\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSUCCESS\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exp:\n",
      "Cell \u001b[0;32mIn [5], line 57\u001b[0m, in \u001b[0;36mImmoWeltScraper._scrape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mfor\u001b[39;00m expose_url \u001b[39min\u001b[39;00m expose_urls:\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdriver\u001b[39m.\u001b[39mget(expose_url)\n\u001b[0;32m---> 57\u001b[0m     property_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_property_data(\n\u001b[1;32m     58\u001b[0m         property_category,\n\u001b[1;32m     59\u001b[0m         buy_category,\n\u001b[1;32m     60\u001b[0m         state\n\u001b[1;32m     61\u001b[0m     )\n\u001b[1;32m     62\u001b[0m     state_property_data\u001b[39m.\u001b[39mappend(property_data)\n\u001b[1;32m     63\u001b[0m     total_property_data\u001b[39m.\u001b[39mappend(property_data)\n",
      "Cell \u001b[0;32mIn [5], line 326\u001b[0m, in \u001b[0;36mImmoWeltScraper._get_property_data\u001b[0;34m(self, category, buy_rent, state)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_property_data\u001b[39m(\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    322\u001b[0m     category: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    323\u001b[0m     buy_rent: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    324\u001b[0m     state: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m--> 326\u001b[0m     soup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_expand_read_more_areas()\n\u001b[1;32m    327\u001b[0m     overview_container \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_overview_container(soup)\n\u001b[1;32m    329\u001b[0m     url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdriver\u001b[39m.\u001b[39mcurrent_url\n",
      "Cell \u001b[0;32mIn [5], line 197\u001b[0m, in \u001b[0;36mImmoWeltScraper._expand_read_more_areas\u001b[0;34m(self, err_loop)\u001b[0m\n\u001b[1;32m    189\u001b[0m     script_expand_all_read_more \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    190\u001b[0m \u001b[39m    let links = document.getElementsByClassName(\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlink--read-more\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m);\u001b[39m\n\u001b[1;32m    191\u001b[0m \u001b[39m    while(links.length > 0) \u001b[39m\u001b[39m{\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m    }\u001b[39m\n\u001b[1;32m    195\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    196\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdriver\u001b[39m.\u001b[39mexecute_script(script_expand_all_read_more)\n\u001b[0;32m--> 197\u001b[0m     \u001b[39mreturn\u001b[39;00m BeautifulSoup(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdriver\u001b[39m.\u001b[39;49mpage_source)\n\u001b[1;32m    198\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exp:\n\u001b[1;32m    199\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEXEPTION!!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:550\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    541\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpage_source\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    542\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[39m    Gets the source of the current page.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39m            driver.page_source\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET_PAGE_SOURCE)[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:442\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m    440\u001b[0m         params[\u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[0;32m--> 442\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m    444\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py:294\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    292\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[1;32m    293\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 294\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py:316\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    313\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 316\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    317\u001b[0m     statuscode \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/site-packages/urllib3/request.py:74\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     71\u001b[0m urlopen_kw[\u001b[39m\"\u001b[39m\u001b[39mrequest_url\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m url\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_url_methods:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39;49mfields, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[1;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[1;32m     80\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/site-packages/urllib3/request.py:96\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_url\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m fields:\n\u001b[1;32m     94\u001b[0m     url \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m urlencode(fields)\n\u001b[0;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf-env-ds-23/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "immo_scraper = ImmoWeltScraper(\n",
    "    BASE_URL,\n",
    "    STATES,\n",
    "    HITS_PER_PAGE,\n",
    "    PROPERTY_CATEGORIES,\n",
    "    BUY_CATEGORIES\n",
    ")\n",
    "immo_scraper.scrape()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env-ds-23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3253a6cf79e429c9826c29a7829299de4ce5c577966b4dbc86f69efa80fc7c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
