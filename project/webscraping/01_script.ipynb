{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebScraping on ImmoWelt.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import bs4\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import ResultSet\n",
    "from bs4.element import Tag as HtmlTag\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUY_CATEGORIES = [\"kaufen\"]  # [\"kaufen\", \"mieten\"]\n",
    "PROPERTY_CATEGORIES = [\"wohnungen\", \"haeuser\"]\n",
    "HITS_PER_PAGE = 20\n",
    "BASE_URL = \"https://www.immowelt.de/liste/${state}/${property_category}/${buy_category}?d=true&efs=NEW_BUILDING_PROJECT&sd=DESC&sf=RELEVANCE&sp=${page}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = \"Baden-Württemberg, Bayern, Berlin, Brandenburg, Bremen, Hamburg, Hessen, Mecklenburg-Vorpommern, Niedersachsen, Nordrhein-Westfalen, Rheinland-Pfalz, Saarland, Sachsen, Sachsen-Anhalt, Schleswig-Holstein, Thüringen\"\n",
    "states = states.replace(\"ü\", \"ue\").lower().split(\", \")\n",
    "STATES = [f\"bl-{state}\" for state in states]\n",
    "STATES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Plan\n",
    "\n",
    "<ol>\n",
    "    <li>Get list of Properties</li>\n",
    "    <li>Calculate the total Property pages count</li>\n",
    "    <li>Get list of Expose URLs of the page</li>\n",
    "    <li>Navigate to the Page and grab the Infos you want</li>\n",
    "    <li>Loop</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImmoWeltScraper:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_url: str,\n",
    "        states: list[str],\n",
    "        hits_per_page: int,\n",
    "        property_categories: list[str],\n",
    "        buy_categories: list[str],\n",
    "    ) -> None:\n",
    "        self.TIME_DELAY = 60 * 2.5\n",
    "        self.driver: webdriver.Chrome = None\n",
    "\n",
    "        self.base_url = base_url\n",
    "        self.states = states\n",
    "        self.hits_per_page = hits_per_page\n",
    "        self.property_categories = property_categories\n",
    "        self.buy_categories = buy_categories\n",
    "    \n",
    "    def scrape(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            self._create_driver()\n",
    "            df = self._scrape()\n",
    "            self._log(\"Script successful finished!\", \"SUCCESS\")\n",
    "        except Exception as exp:\n",
    "            self._destroy_driver()\n",
    "            self._log(\"Script failed. Try again!\", \"ERR\")\n",
    "            self._log(str(exp), \"ERR_MSG\")\n",
    "            # raise exp\n",
    "    \n",
    "    def _scrape(self) -> pd.DataFrame:\n",
    "        total_loops = len(self.states) * len(self.property_categories) * len(self.buy_categories)\n",
    "        curr_loop = 0\n",
    "        total_property_data: list[dict] = []\n",
    "        for state in self.states:\n",
    "            state_property_data: list[dict] = []\n",
    "            for property_category in self.property_categories:\n",
    "                for buy_category in self.buy_categories:\n",
    "                    curr_loop += 1\n",
    "                    self._log(f\"Current-Loop: {curr_loop} of {total_loops}\")\n",
    "                    url = self._get_prep_url(state, property_category, buy_category)\n",
    "                    soup = self._navigate_to(url)\n",
    "                    if not self._is_page_found(soup):\n",
    "                        continue\n",
    "                    \n",
    "                    page_count = self._calc_total_relevant_page_count(soup)\n",
    "                    page_count = 2 if page_count > 2 else page_count  # just for testing\n",
    "                    for i in range(0, page_count):\n",
    "                        page = i + 1\n",
    "                        self._log(f\"State: {state}, category: {property_category}, type: {buy_category}, page: {page} of {page_count}\")\n",
    "                        page_url = self._get_prep_url_page(url, page)\n",
    "                        soup = self._navigate_to(url)\n",
    "\n",
    "                        expose_urls = self._get_expose_urls(soup)\n",
    "                        for expose_url in expose_urls:\n",
    "                            self.driver.get(expose_url)\n",
    "                            property_data = self._get_property_data(\n",
    "                                property_category,\n",
    "                                buy_category,\n",
    "                                state\n",
    "                            )\n",
    "                            state_property_data.append(property_data)\n",
    "                            total_property_data.append(property_data)\n",
    "                self._log(f\"Category delay of {self.TIME_DELAY}s\", \"SLEEP\")\n",
    "                time.sleep(self.TIME_DELAY)\n",
    "            filepath = f\"./data/property_immowelt_{state}.csv\"\n",
    "            _ = self._export(total_property_data, filepath)\n",
    "            self._log(f\"State delay of {self.TIME_DELAY}s\", \"SLEEP\")\n",
    "            time.sleep(self.TIME_DELAY)\n",
    "        filepath = \"./data/property_immowelt_data.csv\"\n",
    "        return self._export(total_property_data, filepath)\n",
    "\n",
    "    def scrape_obj_test(\n",
    "        self,\n",
    "        expose_url: str,\n",
    "    ) -> dict:\n",
    "        self._create_driver()\n",
    "        soup = self._navigate_to(expose_url)\n",
    "        property_data = self._get_property_data(\n",
    "            soup,\n",
    "            \"property_category\",\n",
    "            \"buy_category\",\n",
    "            \"state\"\n",
    "        )\n",
    "        self._destroy_driver()\n",
    "        return property_data\n",
    "\n",
    "    def _create_driver(self) -> None:\n",
    "        if self.driver:\n",
    "            self._destroy_driver()\n",
    "        options = Options()\n",
    "        options.add_argument(\"--headless\")\n",
    "        self.driver = webdriver.Chrome(\n",
    "            service=Service(\n",
    "                ChromeDriverManager().install()\n",
    "            ),\n",
    "            options=options\n",
    "        )\n",
    "        self._log(\"Driver created\")\n",
    "        self._check_permission_requirements()\n",
    "        self._log(\"Permissions accepted\")\n",
    "\n",
    "    def _destroy_driver(self) -> None:\n",
    "        self._log(\"Destroy driver\")\n",
    "        if not self.driver:\n",
    "            return\n",
    "        self.driver.close()\n",
    "        self.driver = None\n",
    "\n",
    "    def _check_permission_requirements(self, err_loop: int = 0):\n",
    "        try:\n",
    "            self.driver.get(\"https://www.immowelt.de/immobilienpreise\")\n",
    "            check_element = None\n",
    "            while not check_element:\n",
    "                check_element = self.driver.execute_script(\n",
    "                    \"\"\"return document.querySelector('#usercentrics-root').shadowRoot.querySelector(\"button[data-testid='uc-accept-all-button']\")\"\"\"\n",
    "                )\n",
    "                if check_element:\n",
    "                    check_element.click()\n",
    "                else:\n",
    "                    self._log(\"Permission loop. Wait 2 seconds.\")\n",
    "                    time.sleep(2)\n",
    "        except Exception as exp:\n",
    "            err_loop += 1\n",
    "            if err_loop == 5:\n",
    "                raise exp\n",
    "            self._log(f\"Permission ERR#{err_loop}-loop\", \"WARN\")\n",
    "            self._check_permission_requirements(err_loop)\n",
    "\n",
    "    def _export(self, data: list[dict], filepath: str) -> pd.DataFrame:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.replace(\"|\", \"_\", inplace=True)\n",
    "        df.to_csv(filepath, sep=\"|\", index=False)\n",
    "        self._log(f\"CSV-Export to: {filepath}\")\n",
    "        return df\n",
    "\n",
    "    def _navigate_to(self, url: str) -> BeautifulSoup:\n",
    "        self.driver.get(url)\n",
    "        return BeautifulSoup(self.driver.page_source)\n",
    "\n",
    "    def _is_page_found(self, soup: BeautifulSoup) -> bool:\n",
    "        is_page_found = not soup.find(\"div\", {\"class\": \"NotFound-d39a0\"})\n",
    "        if not is_page_found:\n",
    "            url = self.driver.current_url\n",
    "            self._log(f\"Page not Found: {url}\", \"ERROR\")\n",
    "        return is_page_found\n",
    "\n",
    "    def _log(self, msg: str, tag: str = \"INFO\") -> None:\n",
    "        tag = tag.upper()\n",
    "        ts = datetime.now().strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "        print(f\"[{ts}] {tag}:\\t{msg}\")\n",
    "\n",
    "    def _get_prep_url(\n",
    "        self,\n",
    "        state: str,\n",
    "        property_category: str,\n",
    "        buy_category: str,\n",
    "        page: int = 1\n",
    "    ) -> str:\n",
    "        page = str(page)\n",
    "        return (\n",
    "            self.base_url\n",
    "                .replace(\"${state}\", state)\n",
    "                .replace(\"${property_category}\", property_category)\n",
    "                .replace(\"${buy_category}\", buy_category)\n",
    "                .replace(\"${page}\", page)\n",
    "        )\n",
    "\n",
    "    def _get_prep_url_page(self, url: str, page: int) -> str:\n",
    "        url_page_removed = url[:url.find(\"sp=\")]\n",
    "        return f\"{url_page_removed}sp={page}\"\n",
    "\n",
    "    def _calc_total_relevant_page_count(self, soup: BeautifulSoup) -> int:\n",
    "        hits_emt = soup.find(\"h1\", {\"class\": \"MatchNumber-a225f\"})\n",
    "        if not hits_emt:\n",
    "            return 0\n",
    "        content = hits_emt.text\n",
    "        hits = content[:content.find(\" \")].replace(\".\", \"\")\n",
    "        hits = int(int(hits) * 0.8)\n",
    "        page_count = int(hits / self.hits_per_page)\n",
    "        return page_count\n",
    "\n",
    "    def _get_expose_urls(self, soup: BeautifulSoup) -> list[str]:\n",
    "        expose_urls_emt = soup.find_all(\"a\", {\"class\": \"mainSection-b22fb\"})\n",
    "        expose_urls = [link[\"href\"] for link in expose_urls_emt]\n",
    "        return expose_urls\n",
    "\n",
    "    def _expand_read_more_areas(self, err_loop = 0) -> BeautifulSoup:\n",
    "        try:\n",
    "            script_expand_all_read_more = \"\"\"\n",
    "            let links = document.getElementsByClassName(\"link--read-more\");\n",
    "            while(links.length > 0) {\n",
    "                links[0].click(); \n",
    "                links = document.getElementsByClassName(\"link--read-more\");\n",
    "            }\n",
    "            \"\"\"\n",
    "            self.driver.execute_script(script_expand_all_read_more)\n",
    "            return BeautifulSoup(self.driver.page_source)\n",
    "        except Exception as exp:\n",
    "            print(\"EXEPTION!!\")\n",
    "            if err_loop >= 5:\n",
    "                raise exp\n",
    "            err_loop += + 1\n",
    "            self._log(f\"Can't expand read-more. Try: {err_loop} of 5\", \"WARN\")\n",
    "            self._expand_read_more_areas(err_loop)\n",
    "\n",
    "    def _get_overview_container(self, soup: BeautifulSoup) -> HtmlTag:\n",
    "        return soup.find(\"app-objectmeta\", {\"id\": \"aUebersicht\"})\n",
    "    \n",
    "    def _get_data_title(self, overview_container: HtmlTag) -> str:\n",
    "        emt = overview_container.find(\"h1\", {\"class\": \"ng-star-inserted\"})\n",
    "        return emt.text if emt else \"Na\"\n",
    "    \n",
    "    def _get_data_hardfacts(self, overview_container: HtmlTag) -> tuple[str, str, str]:\n",
    "        hardfact_emts = overview_container.find_all(\"div\", {\"class\": \"hardfact ng-star-inserted\"})\n",
    "\n",
    "        def prep_text(emt):\n",
    "            content: str = emt.text.strip()\n",
    "            return content[:content.find(\" \")]\n",
    "\n",
    "        price = prep_text(hardfact_emts[0])\n",
    "        living_space = prep_text(hardfact_emts[1])\n",
    "        rooms = prep_text(hardfact_emts[2])\n",
    "        \n",
    "        return price, living_space, rooms\n",
    "    \n",
    "    def _get_data_badges(self, overview_container: BeautifulSoup) -> str:\n",
    "        badge_emts = overview_container.find_all(\"sd-badge\")\n",
    "        badges = \"Na\"\n",
    "        if badge_emts:\n",
    "            badges = \";\".join([legal_info.text for legal_info in badge_emts])\n",
    "        return badges\n",
    "\n",
    "    def _get_data_ratings(self, soup: BeautifulSoup) -> tuple[str, str]:\n",
    "        rating_emts = soup.find_all(\"div\", {\"class\": \"rating-meter__value\"})\n",
    "        location_rating = \"Na\"\n",
    "        public_transport_rating = \"Na\"\n",
    "        if len(rating_emts) == 2:\n",
    "            location_rating = rating_emts[0].text\n",
    "            public_transport_rating = rating_emts[1].text\n",
    "        return location_rating, public_transport_rating\n",
    "\n",
    "    def _get_data_equipments(self, soup: BeautifulSoup) -> str:\n",
    "        equipment_container = soup.find(\"div\", {\"class\": \"equipment card-content ng-star-inserted\"})\n",
    "        if not equipment_container:\n",
    "            return \"Na\"\n",
    "\n",
    "        equipment_cells = equipment_container.find_all(\"sd-cell-row\", {\"class\": \"cell__row\"})\n",
    "        if not equipment_cells:\n",
    "            return \"Na\"\n",
    "\n",
    "        equipments = \"\"\n",
    "        equipment_cell: HtmlTag\n",
    "        for equipment_cell in equipment_cells:\n",
    "            values = equipment_cell.find_all(\"p\")\n",
    "            if len(values) >= 2:\n",
    "                title = values[0].text\n",
    "                value = values[1].text\n",
    "                equipments += f\"{title}: {value};\"\n",
    "\n",
    "        return equipments[:len(equipments)-1] if equipments else \"Na\"\n",
    "    \n",
    "    def _get_data_features(self, soup: BeautifulSoup) -> str:\n",
    "        feature_list_emts = soup.find_all(\"div\", {\"class\": \"textlist\"})\n",
    "        if not feature_list_emts:\n",
    "            return \"Na\"\n",
    "        features = \"\"\n",
    "        feature_list_emt: HtmlTag\n",
    "        for feature_list_emt in feature_list_emts:\n",
    "            feature_emts = feature_list_emt.find_all(\"li\")\n",
    "            if feature_emts:\n",
    "                feature_emt: HtmlTag\n",
    "                for feature_emt in feature_emts:\n",
    "                    features += f\"{feature_emt.text.strip()};\"\n",
    "\n",
    "        return features[:len(features)-1]\n",
    "\n",
    "    def _get_data_energy_data(self, soup: BeautifulSoup) -> str:\n",
    "        energy_data = \"\"\n",
    "\n",
    "        def get_data(curr_energy_data: str, energy_cells: ResultSet) -> str:\n",
    "            if not energy_cells:\n",
    "                return curr_energy_data\n",
    "\n",
    "            energy_cell: HtmlTag\n",
    "            for energy_cell in energy_cells:\n",
    "                content_emts = energy_cell.find_all(\"p\")\n",
    "                title = content_emts[0].text\n",
    "                content = content_emts[1].text\n",
    "                curr_energy_data += f\"{title}: {content};\"\n",
    "\n",
    "            return curr_energy_data\n",
    "\n",
    "        energy_container1 = soup.find(\"app-energy-equipment\")\n",
    "        if energy_container1:\n",
    "            energy_cells = energy_container1.find_all(\"sd-cell-col\", {\"data-cy\": \"energy-equipment\"})\n",
    "            energy_data = get_data(energy_data, energy_cells)\n",
    "\n",
    "        energy_container2 = soup.find(\"div\", {\"class\": \"energy_information ng-star-inserted\"})\n",
    "        if energy_container2:\n",
    "            energy_cells = energy_container2.find_all(\"sd-cell-col\", {\"class\": \"cell__col\"})\n",
    "            energy_data = get_data(energy_data, energy_cells)\n",
    "\n",
    "        return energy_data[:len(energy_data)]\n",
    "\n",
    "    def _get_data_keywords(self, soup: BeautifulSoup) -> str:\n",
    "        read_more_emts = soup.find_all(\"sd-read-more\")\n",
    "        keywords = \"Na\"\n",
    "        if not read_more_emts:\n",
    "            return keywords\n",
    "\n",
    "        last_emt_idx = len(read_more_emts) - 1\n",
    "        keywords: str = read_more_emts[last_emt_idx].text\n",
    "        KEYWORDS_NAME = \"Stichworte\"\n",
    "        if not KEYWORDS_NAME in keywords:\n",
    "            return keywords\n",
    "        start_idx = keywords.find(KEYWORDS_NAME) + len(KEYWORDS_NAME)\n",
    "        keywords = keywords[start_idx:]\n",
    "        return keywords\n",
    "\n",
    "    def _get_property_data(\n",
    "        self,\n",
    "        category: str,\n",
    "        buy_rent: str,\n",
    "        state: str,\n",
    "    ) -> dict:\n",
    "        soup = self._expand_read_more_areas()\n",
    "        overview_container = self._get_overview_container(soup)\n",
    "\n",
    "        url = self.driver.current_url\n",
    "        title = self._get_data_title(overview_container)\n",
    "        price, living_space, rooms = self._get_data_hardfacts(overview_container)\n",
    "        badges = self._get_data_badges(overview_container)\n",
    "        rating_location, rating_public_transport = self._get_data_ratings(soup)\n",
    "        equipments = self._get_data_equipments(soup)\n",
    "        features = self._get_data_features(soup)\n",
    "        energy_data = self._get_data_energy_data(soup)\n",
    "        keywords = self._get_data_keywords(soup)\n",
    "\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"category\": category,\n",
    "            \"buy_rent\": buy_rent,\n",
    "            \"state\": state,\n",
    "            \"title\": title,\n",
    "            \"price\": price,\n",
    "            \"living_space\": living_space,\n",
    "            \"rooms\": rooms,\n",
    "            \"badges\": badges,\n",
    "            \"rating_location\": rating_location,\n",
    "            \"rating_public_transport\": rating_public_transport,\n",
    "            \"equipments\": equipments,\n",
    "            \"features\": features,\n",
    "            \"energy_data\": energy_data,\n",
    "            \"keywords\": keywords\n",
    "            # image_paths: str,  # later the saved paths!\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immo_scraper = ImmoWeltScraper(\n",
    "    BASE_URL,\n",
    "    STATES,\n",
    "    HITS_PER_PAGE,\n",
    "    PROPERTY_CATEGORIES,\n",
    "    BUY_CATEGORIES\n",
    ")\n",
    "immo_scraper.scrape()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
